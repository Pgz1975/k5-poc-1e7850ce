export interface RealtimeVoiceConfig {
  studentId: string;
  language: 'es-PR' | 'en-US';
  model?: string;
  onTranscription?: (text: string, isUser: boolean) => void;
  onAudioPlayback?: (isPlaying: boolean) => void;
  onError?: (error: Error) => void;
  onConnectionChange?: (connected: boolean) => void;
}

export class RealtimeVoiceClient {
  private ws: WebSocket | null = null;
  private audioContext: AudioContext | null = null;
  private mediaStream: MediaStream | null = null;
  private audioWorklet: AudioWorkletNode | null = null;
  private isConnected = false;
  private config: RealtimeVoiceConfig;
  private audioQueue: Int16Array[] = [];
  private isPlayingAudio = false;
  private projectId = import.meta.env.VITE_SUPABASE_PROJECT_ID || 'meertwtenhlmnlpwxhyz';
  private nextScheduledTime = 0;
  private audioInputEnabled = false;
  private audioChunkBuffer: Int16Array[] = [];
  private MIN_BUFFER_SIZE = 3;
  private sessionStartTime = 0;

  constructor(config: RealtimeVoiceConfig) {
    this.config = config;
    console.log('[RealtimeVoice] ðŸŽ¯ Client initialized with config:', {
      studentId: config.studentId,
      language: config.language,
      hasCallbacks: {
        onTranscription: !!config.onTranscription,
        onAudioPlayback: !!config.onAudioPlayback,
        onError: !!config.onError,
        onConnectionChange: !!config.onConnectionChange
      }
    });
  }

  async connect(token: string): Promise<void> {
    try {
      console.log('[RealtimeVoice] ðŸš€ Starting connection process...');
      console.log('[RealtimeVoice] ðŸ”‘ Token length:', token?.length || 0);
      
      // Initialize audio context
      console.log('[RealtimeVoice] ðŸŽµ Creating AudioContext...');
      this.audioContext = new AudioContext({ sampleRate: 24000 });
      console.log('[RealtimeVoice] âœ… AudioContext created, sample rate:', this.audioContext.sampleRate);

      // Load audio worklet for PCM16 processing
      console.log('[RealtimeVoice] ðŸ“¦ Loading audio worklet module...');
      await this.audioContext.audioWorklet.addModule('/audio-worklet-processor.js');
      console.log('[RealtimeVoice] âœ… Audio worklet loaded successfully');

      // Get microphone access
      console.log('[RealtimeVoice] ðŸŽ¤ Requesting microphone access...');
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      console.log('[RealtimeVoice] âœ… Microphone access granted:', {
        tracks: this.mediaStream.getTracks().length,
        settings: this.mediaStream.getAudioTracks()[0]?.getSettings()
      });

      // Create audio worklet node for input processing
      const source = this.audioContext.createMediaStreamSource(this.mediaStream);
      this.audioWorklet = new AudioWorkletNode(this.audioContext, 'pcm16-processor');
      
      this.audioWorklet.port.onmessage = (event) => {
        if (!this.audioInputEnabled || this.ws?.readyState !== WebSocket.OPEN) {
          return;
        }

        const pcm16Data = event.data as Int16Array;
        this.audioChunkBuffer.push(pcm16Data);

        // Batch audio chunks to ~100ms before sending
        if (this.audioChunkBuffer.length >= 2) {
          const totalLength = this.audioChunkBuffer.reduce((sum, chunk) => sum + chunk.length, 0);
          const combined = new Int16Array(totalLength);
          let offset = 0;
          
          for (const chunk of this.audioChunkBuffer) {
            combined.set(chunk, offset);
            offset += chunk.length;
          }
          
          const base64Audio = this.encodePCM16ToBase64(combined);
          this.ws.send(JSON.stringify({
            type: 'input_audio_buffer.append',
            audio: base64Audio
          }));
          
          this.audioChunkBuffer = [];
        }
      };

      source.connect(this.audioWorklet);
      this.audioWorklet.connect(this.audioContext.destination);
      console.log('[RealtimeVoice] Audio pipeline connected');

      // Connect to WebSocket relay
      const modelParam = this.config.model ? `&model=${encodeURIComponent(this.config.model)}` : '';
      const wsUrl = `wss://${this.projectId}.supabase.co/functions/v1/realtime-voice-relay?jwt=${token}&student_id=${this.config.studentId}&language=${this.config.language}${modelParam}`;
      console.log('[RealtimeVoice] ðŸ”Œ Connecting to WebSocket...');
      console.log('[RealtimeVoice] ðŸ“ Project ID:', this.projectId);
      console.log('[RealtimeVoice] ðŸŽ¯ Model:', this.config.model || 'default');
      console.log('[RealtimeVoice] ðŸŒ WebSocket URL:', wsUrl.replace(token, 'TOKEN_HIDDEN'));
      
      this.ws = new WebSocket(wsUrl);
      console.log('[RealtimeVoice] ðŸ”„ WebSocket state:', this.ws.readyState);

      this.ws.onopen = () => {
        console.log('[RealtimeVoice] âœ… WebSocket connected');
        this.isConnected = true;
        this.sessionStartTime = Date.now();
        this.config.onConnectionChange?.(true);
      };

      this.ws.onmessage = async (event) => {
        try {
          const message = JSON.parse(event.data);
          this.handleServerMessage(message);
        } catch (error) {
          console.error('[RealtimeVoice] Error parsing message:', error);
        }
      };

      this.ws.onerror = (error) => {
        console.error('[RealtimeVoice] âŒ WebSocket error:', error);
        this.config.onError?.(new Error('WebSocket connection error'));
      };

      this.ws.onclose = (event) => {
        console.log('[RealtimeVoice] WebSocket closed - Code:', event.code, 'Reason:', event.reason);
        this.isConnected = false;
        this.config.onConnectionChange?.(false);
      };

    } catch (error) {
      console.error('[RealtimeVoice] Connection error:', error);
      this.config.onError?.(error as Error);
      throw error;
    }
  }

  private handleServerMessage(message: any): void {
    const eventTime = Date.now() - this.sessionStartTime;
    console.log(`[RealtimeVoice] [+${eventTime}ms] Server message:`, message.type);

    switch (message.type) {
      case 'session.created':
        console.log('[RealtimeVoice] âœ… Session created - enabling audio input');
        this.enableAudioInput();
        break;

      case 'session.updated':
        console.log('[RealtimeVoice] âœ… Session updated');
        break;

      case 'response.audio.delta':
        this.handleAudioDelta(message.delta);
        break;

      case 'response.audio.done':
        console.log('[RealtimeVoice] Audio response complete');
        this.config.onAudioPlayback?.(false);
        break;

      case 'response.audio_transcript.delta':
        console.log('[RealtimeVoice] ðŸ”Š AI:', message.delta);
        this.config.onTranscription?.(message.delta, false);
        break;

      case 'conversation.item.input_audio_transcription.completed':
        console.log('[RealtimeVoice] ðŸŽ¤ User:', message.transcript);
        this.config.onTranscription?.(message.transcript, true);
        break;

      case 'error':
        console.error('[RealtimeVoice] âŒ Server error:', message.error);
        this.config.onError?.(new Error(message.error.message || 'Unknown error'));
        break;

      default:
        console.log('[RealtimeVoice] Event:', message.type);
    }
  }

  private handleAudioDelta(base64Audio: string): void {
    try {
      const pcm16Data = this.decodeBase64ToPCM16(base64Audio);
      this.audioQueue.push(pcm16Data);
      
      console.log(`[RealtimeVoice] Audio delta received - Queue: ${this.audioQueue.length} chunks`);
      
      // Start playback once we have minimum buffer
      if (!this.isPlayingAudio && this.audioQueue.length >= this.MIN_BUFFER_SIZE) {
        console.log('[RealtimeVoice] Buffer filled, starting playback');
        this.playNextAudioChunk();
      }
    } catch (error) {
      console.error('[RealtimeVoice] Error handling audio delta:', error);
    }
  }

  private async playNextAudioChunk(): Promise<void> {
    if (this.audioQueue.length === 0) {
      this.isPlayingAudio = false;
      this.nextScheduledTime = 0;
      this.config.onAudioPlayback?.(false);
      return;
    }

    this.isPlayingAudio = true;
    this.config.onAudioPlayback?.(true);

    const pcm16Data = this.audioQueue.shift()!;
    
    try {
      if (!this.audioContext) return;

      // Convert PCM16 to Float32
      const float32Data = new Float32Array(pcm16Data.length);
      for (let i = 0; i < pcm16Data.length; i++) {
        float32Data[i] = pcm16Data[i] / 32768.0;
      }

      // Create audio buffer
      const audioBuffer = this.audioContext.createBuffer(1, float32Data.length, 24000);
      audioBuffer.getChannelData(0).set(float32Data);

      // Calculate when to play this chunk
      const now = this.audioContext.currentTime;
      const scheduledTime = Math.max(now, this.nextScheduledTime || now);
      const duration = audioBuffer.duration;

      // Play audio at scheduled time
      const source = this.audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(this.audioContext.destination);
      
      source.onended = () => {
        this.playNextAudioChunk();
      };

      source.start(scheduledTime);
      
      // Update next scheduled time for seamless playback
      this.nextScheduledTime = scheduledTime + duration;
      
      const bufferAhead = (this.nextScheduledTime - now) * 1000;
      console.log(`[RealtimeVoice] Playing chunk: ${pcm16Data.length} samples, duration: ${(duration * 1000).toFixed(0)}ms, buffer ahead: ${bufferAhead.toFixed(0)}ms, queue: ${this.audioQueue.length}`);

    } catch (error) {
      console.error('[RealtimeVoice] Error playing audio:', error);
      this.playNextAudioChunk();
    }
  }

  private enableAudioInput(): void {
    console.log('[RealtimeVoice] ðŸŽ¤ Audio input enabled');
    this.audioInputEnabled = true;
  }

  private encodePCM16ToBase64(pcm16Data: Int16Array): string {
    const uint8Array = new Uint8Array(pcm16Data.buffer);
    let binary = '';
    const chunkSize = 0x8000;
    
    for (let i = 0; i < uint8Array.length; i += chunkSize) {
      const chunk = uint8Array.subarray(i, Math.min(i + chunkSize, uint8Array.length));
      binary += String.fromCharCode(...Array.from(chunk));
    }
    
    return btoa(binary);
  }

  private decodeBase64ToPCM16(base64: string): Int16Array {
    const binary = atob(base64);
    const bytes = new Uint8Array(binary.length);
    
    for (let i = 0; i < binary.length; i++) {
      bytes[i] = binary.charCodeAt(i);
    }
    
    return new Int16Array(bytes.buffer);
  }

  sendText(text: string): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('[RealtimeVoice] Cannot send text: WebSocket not connected');
      return;
    }

    console.log('[RealtimeVoice] Sending text:', text);

    this.ws.send(JSON.stringify({
      type: 'conversation.item.create',
      item: {
        type: 'message',
        role: 'user',
        content: [{ type: 'input_text', text }]
      }
    }));

    this.ws.send(JSON.stringify({ type: 'response.create' }));
  }

  disconnect(): void {
    console.log('[RealtimeVoice] Disconnecting...');

    if (this.audioWorklet) {
      this.audioWorklet.disconnect();
      this.audioWorklet = null;
    }

    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop());
      this.mediaStream = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }

    this.isConnected = false;
    this.audioQueue = [];
    this.audioChunkBuffer = [];
    this.isPlayingAudio = false;
    this.audioInputEnabled = false;
    this.nextScheduledTime = 0;
    
    console.log('[RealtimeVoice] Disconnected');
  }

  isActive(): boolean {
    return this.isConnected;
  }
}

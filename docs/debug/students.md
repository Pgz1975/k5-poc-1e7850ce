1. The Login button and text boxes show no visual or sound feedback when pressed. Users may double-click or think the system is frozen. Input fields do not highlight on focus, limiting accessibility.                              Add feedback (color change, small glow, or sound) when the Login button is clicked. Highlight active fields with a visible border animation. Add a short loading indicator after pressing Login to show that the system is working.

2. lessons pages /lesson/id : The buttons (Volver and Marcar como Completada) work technically well, responding immediately to clicks. However, both share similar size, placement, and color tone, which may confuse young learners who cannot yet read. There is no sound or animation indicating which button should be pressed next. The avatar moves, but without a clear visual link to the correct button.                                                                                        Differentiate buttons by color and shape (e.g., “Continue” in bright green, “Back” in gray). Add an animation or voice prompt when the correct action is required. Include a soft glow or bouncing motion on the Marcar como Completada button when it’s time to click it.

3. exercises / lessons : The Volver al Panel button functions correctly and redirects the user immediately; however, system behavior fails to terminate ongoing audio playback when navigation occurs. The lack of an automatic audio stop command leads to overlapping sounds when switching between sections. Implement a script to automatically pause or terminate any audio playback upon navigation to a new section. Add confirmation that all audio processes have stopped to maintain interface stability and prevent confusion.

4. student dashboard : The Coquí avatar is static and does not respond to user presence or interaction. There is no speech output, dynamic animation, or audio feedback when navigating through the dashboard. As a result, the “learning companion” element feels inactive and disconnected from the educational experience.                                            Activate the bot/AI assistant functionality for the avatar. It should greet the user, describe options, and provide hints (“You have finished 94% of your lessons! Let’s go to exercises next!”). Add event-based triggers for when a button is hovered or clicked, to make navigation more interactive.

5. student dashboard : The bot does not activate upon user interaction, and voice recognition does not capture or process the student’s speech. The “Start Talking” button does not trigger the microphone API or any AI conversational response. This means the voice interaction system (bot module) is either disconnected from the UI trigger or not fully implemented. Connect the “Start Talking” button with the backend voice recognition module (ASR/NLP). Enable real-time audio capture with transcription and bot response. Coquí should reply verbally and textually (“Hi! Tell me what you’d like to learn today!”). Add a progress indicator to show when the bot is listening or thinking.

6. student dashboard : When entering the 1st Grade student dashboard, there are no clear written or audio instructions guiding the student on how to navigate or start activities. The user experience depends entirely on trial and error — clicking buttons without understanding their purpose. For early learners, this lack of structure can create confusion and reduce engagement.                                                                                                                           Add an introductory tutorial or short guided animation with Coquí (the avatar) explaining what each button does (e.g., “Click here to start your lessons!”). Include both visual and audio cues for accessibility. A step-by-step onboarding pop-up for first-time users would also improve user flow and comprehension. Implement guiding cues, simple floating bublles to guide the children through the dashboard. Make modifications gloablly acrosse the complete platform for all grades.

7. exercises : When entering each exercise, there is a noticeable delay before the audio instructions play. After the voice prompt, students are instructed to repeat or respond, but the system does not react to their speech — no validation, feedback, or progression occurs. The activity remains idle even when the correct answer is spoken aloud. This causes confusion, particularly for early learners relying on voice cues.                                                      Synchronize the start of the exercise audio and voice input detection. Integrate a clear event trigger after the spoken input — if the pronunciation is recognized as correct, the system should immediately confirm (“Correct! The word starts with M”) and proceed to the next exercise. If incorrect, it should offer gentle feedback (“Try again, listen carefully”). Add a short animation or sound confirmation to reinforce successful responses.

# Open Source Research - Speech-to-Text & Reading Tools
## Libraries and Tools for Realtime Demo Implementation

**Document Version:** 1.0
**Last Updated:** October 28, 2025
**Research Focus:** Production-ready, well-maintained libraries

---

## üéØ Research Objectives

Find battle-tested open-source solutions for:
1. **Word-level speech-to-text** with timestamps
2. **Real-time word highlighting** synchronized with speech
3. **Pronunciation assessment** tools
4. **Fuzzy string matching** for transcription
5. **Reading metrics** calculation (WCPM, fluency)
6. **Audio visualization** components

---

## üé§ Speech-to-Text Libraries

### 1. **Web Speech API** (Native Browser)
**URL:** https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API
**License:** W3C Standard (Free)
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)

**Pros:**
- ‚úÖ Native browser support (Chrome, Edge, Safari)
- ‚úÖ Real-time transcription with continuous mode
- ‚úÖ No API costs
- ‚úÖ Language support including Spanish
- ‚úÖ Confidence scores available
- ‚úÖ Simple integration

**Cons:**
- ‚ùå No word-level timestamps (sentence-level only)
- ‚ùå Limited to browser environment
- ‚ùå Varying quality across browsers
- ‚ùå No offline support

**Implementation Example:**
```javascript
const recognition = new webkitSpeechRecognition();
recognition.continuous = true;
recognition.interimResults = true;
recognition.lang = 'es-PR';

recognition.onresult = (event) => {
  for (let i = event.resultIndex; i < event.results.length; i++) {
    const transcript = event.results[i][0].transcript;
    const confidence = event.results[i][0].confidence;
    const isFinal = event.results[i].isFinal;

    // Process transcript
    if (isFinal) {
      handleFinalTranscript(transcript, confidence);
    }
  }
};
```

**Recommendation:** Use as **fallback** if OpenAI Realtime API transcription fails.

---

### 2. **Whisper.cpp** (Local Inference)
**URL:** https://github.com/ggerganov/whisper.cpp
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (3/5)

**Pros:**
- ‚úÖ OpenAI Whisper model in C++ (fast)
- ‚úÖ Word-level timestamps available
- ‚úÖ High accuracy (especially for Spanish)
- ‚úÖ Can run in browser via WASM
- ‚úÖ Offline capable

**Cons:**
- ‚ùå Requires model download (~140MB for base model)
- ‚ùå Initial load time
- ‚ùå Higher computational requirements
- ‚ùå Not real-time (post-processing)

**Use Case:** Offline demo mode or pronunciation analysis enhancement.

---

### 3. **@huggingface/transformers** (JS Library)
**URL:** https://github.com/xenova/transformers.js
**License:** Apache 2.0
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)

**Pros:**
- ‚úÖ Already in project dependencies!
- ‚úÖ Whisper models in browser
- ‚úÖ Word-level timestamps
- ‚úÖ Extensive model library
- ‚úÖ TypeScript support

**Cons:**
- ‚ùå Large model sizes
- ‚ùå Slower than native solutions
- ‚ùå Not real-time (batch processing)

**Implementation Example:**
```typescript
import { pipeline } from '@huggingface/transformers';

const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny');

const result = await transcriber(audioData, {
  return_timestamps: 'word',
  language: 'spanish'
});

console.log(result);
// {
//   text: "hola mundo",
//   chunks: [
//     { text: "hola", timestamp: [0.0, 0.5] },
//     { text: "mundo", timestamp: [0.6, 1.2] }
//   ]
// }
```

**Recommendation:** Use for **pronunciation analysis** after recording, not real-time.

---

## üìñ Word Highlighting & Synchronization

### 1. **react-textfit** (Text Fitting)
**URL:** https://github.com/malte-wessel/react-textfit
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (2/5)

**Pros:**
- ‚úÖ Responsive text sizing
- ‚úÖ React integration

**Cons:**
- ‚ùå No highlighting features
- ‚ùå Not designed for reading

**Recommendation:** Skip - not needed for our use case.

---

### 2. **Custom Implementation with React State**
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

**Approach:**
```typescript
// Split passage into words with unique IDs
const words = passage.split(/\s+/).map((word, index) => ({
  id: index,
  text: word,
  state: 'pending' // 'pending' | 'correct' | 'error' | 'skipped' | 'current'
}));

// Render with conditional styling
{words.map(word => (
  <span
    key={word.id}
    className={cn({
      'bg-gray-100': word.state === 'pending',
      'bg-green-200': word.state === 'correct',
      'bg-red-200': word.state === 'error',
      'bg-yellow-200': word.state === 'skipped',
      'ring-4 ring-blue-400 scale-110': word.state === 'current'
    })}
  >
    {word.text}
  </span>
))}
```

**Recommendation:** ‚úÖ **Use custom implementation** - full control, no dependencies.

---

### 3. **AutoScroll with `scrollIntoView`**
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

```typescript
function scrollToWord(wordId: number) {
  const element = document.getElementById(`word-${wordId}`);
  element?.scrollIntoView({
    behavior: 'smooth',
    block: 'center',
    inline: 'nearest'
  });
}
```

**Recommendation:** ‚úÖ **Use native browser API** - smooth, performant, no dependencies.

---

## üîä Pronunciation Assessment

### 1. **pronounce-js** (Phonetic Comparison)
**URL:** https://github.com/jantimon/pronounce
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (2/5)

**Status:** Archived, no longer maintained.
**Recommendation:** ‚ùå Skip.

---

### 2. **Levenshtein Distance Algorithms**
**URL:** https://github.com/gustf/js-levenshtein
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

**Pros:**
- ‚úÖ Tiny library (~500 bytes)
- ‚úÖ Fast implementation
- ‚úÖ Perfect for fuzzy matching
- ‚úÖ Well-tested

**Implementation:**
```typescript
import levenshtein from 'js-levenshtein';

function fuzzyMatch(spoken: string, expected: string): number {
  const distance = levenshtein(spoken.toLowerCase(), expected.toLowerCase());
  const maxLength = Math.max(spoken.length, expected.length);
  return 1 - (distance / maxLength);
}

// Usage
const score = fuzzyMatch('perro', 'pero'); // 0.8 (80% match)
```

**Recommendation:** ‚úÖ **Use for pronunciation matching** in ReadFlow and Pronunciation demos.

---

### 3. **Soundex / Metaphone Algorithms**
**URL:** https://github.com/words/natural-soundex
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (3/5)

**Use Case:** Phonetic similarity for English words
**Spanish Support:** Limited

**Recommendation:** ‚ö†Ô∏è Consider for English content only.

---

## üé® Audio Visualization

### 1. **Canvas API** (Native)
**URL:** https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API
**License:** W3C Standard
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

**Implementation:**
```typescript
function drawWaveform(canvas: HTMLCanvasElement, frequencyData: Uint8Array) {
  const ctx = canvas.getContext('2d');
  const width = canvas.width;
  const height = canvas.height;
  const barWidth = width / frequencyData.length;

  ctx.clearRect(0, 0, width, height);

  for (let i = 0; i < frequencyData.length; i++) {
    const value = frequencyData[i];
    const barHeight = (value / 255) * height;
    const x = i * barWidth;
    const y = (height - barHeight) / 2;

    ctx.fillStyle = `hsl(${200 + value / 2}, 70%, 60%)`;
    ctx.fillRect(x, y, barWidth, barHeight);
  }
}
```

**Recommendation:** ‚úÖ **Use native Canvas** - performant, no dependencies.

---

### 2. **wavesurfer.js**
**URL:** https://github.com/wavesurfer-js/wavesurfer.js
**License:** BSD-3-Clause
**Relevance:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (3/5)

**Pros:**
- ‚úÖ Beautiful visualizations
- ‚úÖ Waveform rendering
- ‚úÖ Interactive timeline

**Cons:**
- ‚ùå 50KB+ library
- ‚ùå Designed for audio playback, not live input
- ‚ùå Overkill for our needs

**Recommendation:** ‚ö†Ô∏è Skip - custom Canvas is lighter and more flexible.

---

## üìä Reading Metrics & Analytics

### 1. **Custom WCPM Calculator**
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

```typescript
interface ReadingMetrics {
  wordsCorrect: number;
  wordsTotal: number;
  elapsedSeconds: number;
}

function calculateWCPM(metrics: ReadingMetrics): number {
  const minutes = metrics.elapsedSeconds / 60;
  return Math.round(metrics.wordsCorrect / minutes);
}

function calculateAccuracy(correct: number, total: number): number {
  return total > 0 ? correct / total : 0;
}

function calculateFluencyScore(wcpm: number, accuracy: number, targetWCPM: number): number {
  const speedScore = Math.min(wcpm / targetWCPM, 1) * 100;
  const accuracyScore = accuracy * 100;

  return (speedScore * 0.3) + (accuracyScore * 0.7); // 30% speed, 70% accuracy
}
```

**Recommendation:** ‚úÖ **Implement custom** - simple, tailored to our needs.

---

### 2. **reading-level** (Flesch-Kincaid, etc.)
**URL:** https://github.com/words/reading-level
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (2/5)

**Use Case:** Text complexity analysis (not real-time metrics)
**Recommendation:** ‚ö†Ô∏è Optional - useful for content creation, not demo runtime.

---

## üß™ Testing Libraries

### 1. **@testing-library/react**
**URL:** https://testing-library.com/docs/react-testing-library/intro
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

**Already in project dependencies** (via Vite/React template)

**Use Cases:**
- Component rendering tests
- User interaction simulation
- Accessibility testing

**Recommendation:** ‚úÖ **Use for demo component tests**.

---

### 2. **Mock Audio APIs**
**URL:** https://github.com/goldfire/howler.js (for reference)
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)

**Mock Implementation:**
```typescript
// Mock getUserMedia for tests
global.navigator.mediaDevices = {
  getUserMedia: vi.fn().mockResolvedValue({
    getTracks: () => [
      {
        kind: 'audio',
        stop: vi.fn()
      }
    ]
  } as any)
};

// Mock AudioContext
global.AudioContext = vi.fn(() => ({
  createAnalyser: vi.fn(() => ({
    fftSize: 256,
    frequencyBinCount: 128,
    getByteFrequencyData: vi.fn()
  })),
  createMediaStreamSource: vi.fn(),
  sampleRate: 24000
})) as any;
```

**Recommendation:** ‚úÖ **Implement mocks** for unit tests.

---

## üéØ Function Calling & Voice Commands

### 1. **Natural Language Command Parser**
**URL:** https://github.com/spencermountain/compromise
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (3/5)

**Pros:**
- ‚úÖ Lightweight NLP library
- ‚úÖ Verb/noun extraction
- ‚úÖ Spanish support (via plugin)

**Cons:**
- ‚ùå Not needed if using OpenAI function calling
- ‚ùå Adds complexity

**Recommendation:** ‚ö†Ô∏è Skip - OpenAI handles this natively via function calling.

---

### 2. **Command Pattern with OpenAI Functions**
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

```typescript
const voiceCommandTools = [
  {
    type: 'function',
    name: 'move_item',
    description: 'Move a draggable item to a target zone',
    parameters: {
      type: 'object',
      properties: {
        item: {
          type: 'string',
          enum: ['sun', 'cloud', 'tree', 'flower'],
          description: 'The item to move'
        },
        zone: {
          type: 'string',
          enum: ['sky', 'ground'],
          description: 'Target zone'
        }
      },
      required: ['item', 'zone']
    }
  },
  {
    type: 'function',
    name: 'undo_move',
    description: 'Undo the last move'
  }
];

// Handle function calls
client.registerFunctionHandler('move_item', async ({ item, zone }) => {
  performDragDrop(item, zone);
  return { success: true, message: `Moved ${item} to ${zone}` };
});
```

**Recommendation:** ‚úÖ **Use OpenAI function calling** - most reliable approach.

---

## üåê Multilingual Support

### 1. **Language Detection**
**URL:** Native - OpenAI Realtime API supports language parameter
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)

**Configuration:**
```typescript
{
  audio: {
    input: {
      transcription: {
        model: 'gpt-4o-transcribe',
        language: 'es' // Spanish
      }
    }
  }
}
```

**Recommendation:** ‚úÖ **Use OpenAI native language support**.

---

### 2. **Spanish Pronunciation Resources**
**URL:** https://github.com/topics/spanish-pronunciation
**Relevance:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (3/5)

**Resources:**
- IPA (International Phonetic Alphabet) for Spanish
- Syllable break rules
- Stress patterns

**Recommendation:** üìö **Reference for content creation**, not runtime code.

---

## üîß Utility Libraries

### 1. **fuzzysort** (Fuzzy Search)
**URL:** https://github.com/farzher/fuzzysort
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)

**Pros:**
- ‚úÖ Fast fuzzy search
- ‚úÖ Typo-tolerance
- ‚úÖ Highlighting support
- ‚úÖ TypeScript support

**Implementation:**
```typescript
import fuzzysort from 'fuzzysort';

function matchWord(spoken: string, candidates: string[]): string | null {
  const result = fuzzysort.go(spoken, candidates, { threshold: 0.7 });

  return result.length > 0 ? result[0].target : null;
}

// Usage
const match = matchWord('perro', ['pero', 'perro', 'pera']);
// Returns: 'perro'
```

**Recommendation:** ‚úÖ **Use for word matching** in ReadFlow.

---

### 2. **lodash** (Utilities)
**URL:** https://lodash.com
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (2/5)

**Recommendation:** ‚ö†Ô∏è Only if needed - prefer native JS methods to reduce bundle size.

---

### 3. **date-fns** (Already in Dependencies)
**URL:** https://date-fns.org
**License:** MIT
**Relevance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)

**Use Cases:**
- Timestamp formatting
- Duration calculations
- Timer displays

**Recommendation:** ‚úÖ **Use for time calculations** in speed quiz and metrics.

---

## üì¶ Recommended Dependencies

### Install Commands

```bash
# Essential
npm install js-levenshtein    # Fuzzy matching
npm install fuzzysort          # Word search

# Optional (already have alternatives)
# npm install @huggingface/transformers  # Already installed
# npm install date-fns                    # Already installed
```

### Bundle Size Analysis

| Library | Size (gzipped) | Purpose | Priority |
|---------|----------------|---------|----------|
| js-levenshtein | 0.5 KB | Pronunciation matching | ‚úÖ High |
| fuzzysort | 4 KB | Word matching | ‚úÖ High |
| @huggingface/transformers | ~1 MB | Offline STT | ‚ö†Ô∏è Low |
| Web Speech API | 0 KB (native) | Fallback STT | ‚úÖ High |

**Total Added:** ~4.5 KB

---

## üéØ Implementation Strategy

### Phase 1: Core Dependencies (Day 1)
```bash
npm install js-levenshtein fuzzysort
```

### Phase 2: Custom Implementations (Days 2-3)
- ‚úÖ Canvas-based audio visualization
- ‚úÖ React state for word highlighting
- ‚úÖ Custom WCPM calculator
- ‚úÖ Fuzzy matching wrapper

### Phase 3: OpenAI Integration (Days 4-5)
- ‚úÖ Word-level transcription parsing
- ‚úÖ Function calling setup
- ‚úÖ Voice command handlers

### Phase 4: Fallbacks (Optional)
- ‚ö†Ô∏è Web Speech API integration
- ‚ö†Ô∏è Offline mode with Hugging Face

---

## üìä Comparison Matrix

| Feature | OpenAI Realtime | Web Speech API | Hugging Face | Custom Code |
|---------|----------------|----------------|--------------|-------------|
| **Real-time** | ‚úÖ Yes | ‚úÖ Yes | ‚ùå No | N/A |
| **Word timestamps** | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes | N/A |
| **Spanish support** | ‚úÖ Excellent | ‚úÖ Good | ‚úÖ Excellent | N/A |
| **Cost** | $$ API | Free | Free | Free |
| **Accuracy** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | N/A |
| **Latency** | ~300ms | ~500ms | ~2000ms | N/A |
| **Bundle size** | 0 KB | 0 KB | ~1 MB | Minimal |

**Winner:** ‚úÖ **OpenAI Realtime API** (primary) + **Custom code** (UI/logic)

---

## üéì Learning Resources

### Documentation
1. **OpenAI Realtime API Docs:** https://platform.openai.com/docs/guides/realtime
2. **Web Audio API Guide:** https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API
3. **Canvas Tutorial:** https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial

### Reference Implementations
1. **OpenAI Realtime Console:** https://github.com/openai/openai-realtime-console
2. **Speech Recognition Examples:** https://github.com/mdn/dom-examples/tree/main/web-speech-api
3. **Canvas Visualizations:** https://github.com/processing/p5.js-sound

---

## ‚úÖ Final Recommendations

### ‚úÖ Use These:
1. **OpenAI Realtime API** - Primary STT with word-level transcription
2. **js-levenshtein** - Pronunciation matching
3. **fuzzysort** - Word search and matching
4. **Canvas API** - Audio visualization
5. **Native React State** - Word highlighting
6. **Custom WCPM Calculator** - Reading metrics

### ‚ö†Ô∏è Consider These:
1. **Web Speech API** - Fallback for OpenAI failures
2. **date-fns** (already installed) - Time formatting
3. **@huggingface/transformers** (already installed) - Offline analysis

### ‚ùå Skip These:
1. ‚ùå wavesurfer.js - Too heavy
2. ‚ùå pronounce-js - Unmaintained
3. ‚ùå compromise - Redundant with OpenAI
4. ‚ùå lodash - Use native JS

---

## üìù Implementation Checklist

- [ ] Install js-levenshtein
- [ ] Install fuzzysort
- [ ] Create fuzzy matching utility
- [ ] Implement Canvas visualizer
- [ ] Build word highlighting component
- [ ] Create WCPM calculator
- [ ] Setup OpenAI transcription parsing
- [ ] Implement function calling handlers
- [ ] Add Web Speech API fallback
- [ ] Write unit tests with mocks

---

**Document Status:** ‚úÖ RESEARCH COMPLETE
**Next Action:** Begin implementation with recommended dependencies
**Total Added Dependencies:** 2 (js-levenshtein, fuzzysort)
**Total Bundle Impact:** ~4.5 KB gzipped

**Last Updated:** October 28, 2025
**Version:** 1.0
